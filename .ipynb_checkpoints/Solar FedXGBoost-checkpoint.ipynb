{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbcf364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7232ef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with (open(\"saved_results/clients_data_full\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            data.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daa08292",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One dataframe per household\n",
    "dfs_train = [None]*25\n",
    "dfs_test = [None]*25\n",
    "dfs_big = [None]*25\n",
    "means = [None]*25\n",
    "stds = [None]*25\n",
    "\n",
    "for i in range(len(data[0])):\n",
    "    #Create train dfs\n",
    "    mat_train = np.matrix(data[0][i][0])\n",
    "    dfs_train[i] = pd.DataFrame(mat_train)\n",
    "    dfs_train[i].drop(7, axis = 1, inplace = True)\n",
    "    dfs_train[i]['pred'] = data[0][i][1].tolist()\n",
    "    \n",
    "    #Create test dfs\n",
    "    mat = np.matrix(data[0][i][2])\n",
    "    dfs_test[i] = pd.DataFrame(mat)\n",
    "    dfs_test[i].drop(7, axis = 1, inplace = True)\n",
    "    dfs_test[i]['pred'] = data[0][i][3].tolist()\n",
    "    \n",
    "    dfs_big[i] = dfs_train[i].append(dfs_test[i])\n",
    "    #dfs_big[i] = (dfs_big[i]-dfs_big[i].mean())/dfs_big[i].std()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "c1bb1cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = []\n",
    "\n",
    "df = [None]*len(dfs_big)\n",
    "\n",
    "\n",
    "for i in range(0,3):\n",
    "    df[i] = dfs_big[i].sample(n = 100)\n",
    "    X = df[i].loc[:, df[i].columns != 'pred']\n",
    "\n",
    "\n",
    "    y = df[i].loc[:, df[i].columns == 'pred']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "    \n",
    "    mean_x_t = np.mean(X_train)\n",
    "    std_x_t =  np.std(X_train)\n",
    "\n",
    "    mean_y_t = np.mean(y_train)\n",
    "    std_y_t =  np.std(y_train)\n",
    "\n",
    "    X_train = (X_train-mean_x_t)/std_x_t\n",
    "    y_train = (y_train-mean_y_t)/std_y_t\n",
    "\n",
    "    X_test = (X_test-mean_x_t)/std_x_t\n",
    "    y_test = (y_test-mean_y_t)/std_y_t\n",
    "    \n",
    "    train = X_train.copy()\n",
    "    test = X_test.copy()\n",
    "    \n",
    "    train[\"y\"] = y_train\n",
    "    test['y'] = y_test\n",
    "    \n",
    "    clients.append(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f1f0771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     264\n",
       "1     363\n",
       "2      69\n",
       "3      61\n",
       "4     400\n",
       "5     400\n",
       "6     163\n",
       "8      76\n",
       "9     164\n",
       "10    241\n",
       "11    321\n",
       "12    392\n",
       "13    399\n",
       "y     400\n",
       "g     400\n",
       "h     400\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients[0].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "69e40bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done binning\n",
      "Ready to train tree\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reindex from a duplicate axis",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_928/625603527.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Ready to train tree\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mtree_hist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Ready to search for leaf weight\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_928/2624640867.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(hist, feature, depth, max_depth)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;31m#Find the best split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[0mrule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_best_rule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m     \u001b[0mfeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrule\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"feature\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_928/2624640867.py\u001b[0m in \u001b[0;36mfind_best_rule\u001b[1;34m(hist, features)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m#thresholds = thresholds[1:]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mdf_L\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m             \u001b[0mdf_R\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    960\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    961\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 962\u001b[1;33m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    963\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36mcheck_bool_indexer\u001b[1;34m(index, key)\u001b[0m\n\u001b[0;32m   2383\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2384\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2385\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2386\u001b[0m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mreindex\u001b[1;34m(self, index, **kwargs)\u001b[0m\n\u001b[0;32m   4578\u001b[0m     )\n\u001b[0;32m   4579\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4580\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4582\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mdeprecate_nonkeyword_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallowed_args\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"self\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"labels\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mreindex\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   4816\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4817\u001b[0m         \u001b[1;31m# perform the reindex on the axes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4818\u001b[1;33m         return self._reindex_axes(\n\u001b[0m\u001b[0;32m   4819\u001b[0m             \u001b[0maxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4820\u001b[0m         ).__finalize__(self, method=\"reindex\")\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_reindex_axes\u001b[1;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[0;32m   4837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4838\u001b[0m             \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4839\u001b[1;33m             obj = obj._reindex_with_indexers(\n\u001b[0m\u001b[0;32m   4840\u001b[0m                 \u001b[1;33m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnew_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4841\u001b[0m                 \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_reindex_with_indexers\u001b[1;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[0;32m   4881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4882\u001b[0m             \u001b[1;31m# TODO: speed up on homogeneous DataFrame objects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4883\u001b[1;33m             new_data = new_data.reindex_indexer(\n\u001b[0m\u001b[0;32m   4884\u001b[0m                 \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4885\u001b[0m                 \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice)\u001b[0m\n\u001b[0;32m    668\u001b[0m         \u001b[1;31m# some axes don't allow reindexing with dups\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 670\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_can_reindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    671\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_validate_can_reindex\u001b[1;34m(self, indexer)\u001b[0m\n\u001b[0;32m   3783\u001b[0m         \u001b[1;31m# trying to reindex on an axis with duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_as_unique\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3785\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cannot reindex from a duplicate axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3787\u001b[0m     def reindex(\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reindex from a duplicate axis"
     ]
    }
   ],
   "source": [
    "################## Model 0 ###################\n",
    "f_0 = 0\n",
    "f_m = [f_0]*len(clients)\n",
    "\n",
    "trees = []\n",
    "\n",
    "################## Other models ###################\n",
    "for t in range(1,2):\n",
    "    \n",
    "    binned_client = []\n",
    "\n",
    "    for i in range(1,3):\n",
    "        #Compute gradient and hessian of each sample\n",
    "        clients[i][\"g\"] = 2*(clients[i][\"y\"]-f_m[i])*clients[i][\"y\"]\n",
    "        clients[i][\"h\"] = -2*clients[i][\"y\"]\n",
    "\n",
    "        hists = []\n",
    "        feature = list(clients[i].columns)\n",
    "        del feature[len(feature) - 3:]\n",
    "        b = 20\n",
    "\n",
    "        for j in feature:\n",
    "            df_bin = clients[i][[j,\"g\",\"h\"]].copy()\n",
    "            \n",
    "            df_bin[\"bin\"] = pd.qcut(df_bin[j],b,duplicates='drop')\n",
    "\n",
    "            df_bin = df_bin.groupby('bin', as_index=False)[['g','h']].sum()\n",
    "            df_bin[j] = df_bin[\"bin\"].apply(lambda x :x.mid)\n",
    "\n",
    "            df_bin.drop(\"bin\",axis = 1, inplace = True)\n",
    "\n",
    "            df_bin = df_bin[[j,\"g\",\"h\"]]\n",
    "            hists.append(df_bin)\n",
    "            \n",
    "        binned_client.append(hists)\n",
    "\n",
    "    print(\"Done binning\")\n",
    "    ag = []\n",
    "    for j in range(len(feature)):\n",
    "        aggregator = binned_client[0][j]\n",
    "        \n",
    "        for i in range(len(binned_client)):\n",
    "            aggregator = aggregator.append(binned_client[i][j])\n",
    "        \n",
    "        \n",
    "        agg = merge_hist(aggregator, b,feature[j])\n",
    "        ag.append(agg)\n",
    "        \n",
    "    print(\"Ready to train tree\")\n",
    "    \n",
    "    tree_hist = split(ag,feature,0,2)\n",
    "    \n",
    "    print(\"Ready to search for leaf weight\")\n",
    "\n",
    "    tr = find_leaf_weights_cl(clients, tree_hist)\n",
    "    \n",
    "    trees.append(tr)\n",
    "    \n",
    "    for i in range(len(clients)):\n",
    "        preds = clients[i].apply(predict, axis='columns', rules=tr.copy())\n",
    "        f_m[i] = f_m[i]+preds    \n",
    "        \n",
    "    print(t)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "3e9e2784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212    0.378449\n",
       "244    1.723598\n",
       "74    -1.233411\n",
       "23    -0.481596\n",
       "191    1.427897\n",
       "         ...   \n",
       "206   -0.339338\n",
       "27     0.372574\n",
       "10    -0.424041\n",
       "181    0.779957\n",
       "50    -0.165898\n",
       "Name: 1, Length: 1600, dtype: float64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ag[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0b30da74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature': 11,\n",
       " 'threshold': 2.47125,\n",
       " 'left': {'feature': 11,\n",
       "  'threshold': -0.7989999999999999,\n",
       "  'left': {'prediction': -2.3578034895469673e-16},\n",
       "  'right': {'prediction': 7.883493651402927e-17}},\n",
       " 'right': {'feature': 4,\n",
       "  'threshold': 1.29475,\n",
       "  'left': {'prediction': 4.578839464101955e-16},\n",
       "  'right': {'prediction': 0}}}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "11d83844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.873765250456302"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = X_test.copy()\n",
    "test[\"y\"] = y_test\n",
    "\n",
    "################## Predicting using model ###################\n",
    "preds = 0\n",
    "for i in range(len(trees)):\n",
    "    preds += test.apply(predict, axis='columns', rules=trees[i].copy())\n",
    "preds += np.mean(test[\"y\"])\n",
    "    \n",
    "\n",
    "    \n",
    "################## Calculate RMSE ###################\n",
    "np.sqrt(np.sum(np.power(preds-test[\"y\"],2))/len(preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "94cd8e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature': 4,\n",
       " 'threshold': -1.56994921875,\n",
       " 'left': {'feature': 11,\n",
       "  'threshold': -0.8440449218749999,\n",
       "  'left': {'prediction': -28.29713258237743},\n",
       "  'right': {'prediction': -25.85750280580254}},\n",
       " 'right': {'feature': 4,\n",
       "  'threshold': 1.964,\n",
       "  'left': {'prediction': 956.9978170799645},\n",
       "  'right': {'prediction': 6.963966572545797}}}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "310c780d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to search for leaf weight\n",
      "tag\n",
      "0.087360    44.800819\n",
      "0.406643    -1.845630\n",
      "0.512543     1.834322\n",
      "0.972034    -1.321154\n",
      "Name: w, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "tree_hist = split(ag,feature,0,2)\n",
    "    \n",
    "print(\"Ready to search for leaf weight\")\n",
    "\n",
    "tr = find_leaf_weights_cl(clients, tree_hist)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d164db6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight[weight.index == 2].empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a17468c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_rule(hist,features):\n",
    "    \n",
    "    #X_train with X, g and h for all samples\n",
    "    \n",
    "    best_feature, best_threshold, opt_split = None, None, np.inf\n",
    "    \n",
    "    for i in range(len(hist)):\n",
    "        feat = features[i]\n",
    "        df = hist[i]\n",
    "        thresholds = df[feat].unique().tolist()\n",
    "        thresholds.sort()\n",
    "        #thresholds = thresholds[1:]\n",
    "        for t in thresholds:\n",
    "            df_L =  df[df[feat]<t]\n",
    "            df_R =  df[df[feat]>=t]\n",
    "    \n",
    "            G = np.sum(df[\"g\"])\n",
    "            H = np.sum(df[\"h\"])\n",
    "    \n",
    "            G_L = np.sum(df_L[\"g\"])\n",
    "            G_R = np.sum(df_R[\"g\"])\n",
    "    \n",
    "            H_L = np.sum(df_L[\"h\"])\n",
    "            H_R = np.sum(df_R[\"h\"])\n",
    "            \n",
    "              \n",
    "            if (H==0) or (H_R==0) or (H_L ==0):\n",
    "                continue\n",
    "        \n",
    "            split = 1/2*((G_L*G_L)/H_L + (G_R*G_R)/H_R - (G*G)/H)\n",
    "            \n",
    "            opt_split = min(opt_split, split)\n",
    "            if split == opt_split:\n",
    "                x_opt = t\n",
    "                best_feature = feat\n",
    "    \n",
    "    return {'feature': best_feature, 'threshold': x_opt}\n",
    "\n",
    "\n",
    "def split(hist,feature, depth, max_depth):\n",
    "    if depth == max_depth:\n",
    "        w = []\n",
    "        for i in range(len(hist)):\n",
    "            w.append(-np.sum(hist[1][\"g\"])/np.sum(hist[1][\"h\"]))\n",
    "        return {'prediction': random.random()}\n",
    "    \n",
    "    #Find the best split\n",
    "    rule = find_best_rule(hist, feature)\n",
    "    feat = feature.index(rule[\"feature\"])\n",
    "    \n",
    "    #Split on the rule\n",
    "    left_hist = hist.copy()\n",
    "    right_hist = hist.copy()\n",
    "    \n",
    "    left_ix = hist[feat][rule['feature']] < rule['threshold']\n",
    "    \n",
    "    left_hist[feat] = hist[feat][left_ix]\n",
    "    right_hist[feat] = hist[feat][~left_ix]\n",
    "    \n",
    "    #Find best rule and split on subsamples\n",
    "    rule['left'] = split(left_hist, feature, depth + 1, max_depth)\n",
    "    rule['right'] = split(right_hist, feature, depth + 1, max_depth)\n",
    "    return rule\n",
    "\n",
    "def find_leaf_weights(df,tree):\n",
    "    df[\"tag\"] = df.apply(predict, axis='columns', rules=tree.copy())\n",
    "\n",
    "    weights = df.groupby('tag')[['g','h']].sum()\n",
    "    weights[\"w\"] = -weights[\"g\"]/weights[\"h\"]\n",
    "\n",
    "    df.drop('tag', axis = 1, inplace = True)\n",
    "    weights.drop([\"g\",\"h\"],axis = 1, inplace = True)\n",
    "\n",
    "    paths = [[\"left\",\"left\"],[\"left\",\"right\"],[\"right\",\"left\"],[\"right\",\"right\"]]\n",
    "\n",
    "    for i in paths: \n",
    "        target = tree[i[0]][i[1]][\"prediction\"]\n",
    "        tree[i[0]][i[1]][\"prediction\"] = weights[weights.index == target][\"w\"].values[0]\n",
    "\n",
    "    return tree\n",
    "\n",
    "def find_leaf_weights_cl(clients,tree):\n",
    "    \n",
    "    weights = [None]*len(clients)\n",
    "    \n",
    "    \n",
    "    for i in range(len(clients)):\n",
    "        clients[i][\"tag\"] = clients[i].apply(predict, axis='columns', rules=tree.copy())\n",
    "        weights[i] = clients[i].groupby('tag', as_index = False)[['g','h']].sum()\n",
    "\n",
    "        clients[i].drop('tag', axis = 1, inplace = True)\n",
    "        #weights[i].drop([\"g\",\"h\"],axis = 1, inplace = True)\n",
    "\n",
    "    \n",
    "    weight = weights[0]\n",
    "    for i in range(1,len(weights)):\n",
    "        weight = weight.append(weights[i])\n",
    "    \n",
    "    weight = weight.groupby(\"tag\")[[\"g\",\"h\"]].sum()\n",
    "    \n",
    "    weight[\"w\"] = -weight[\"g\"]/weight[\"h\"]\n",
    "    \n",
    "    weight.drop([\"g\",\"h\"],axis = 1, inplace = True)\n",
    "    \n",
    "    \n",
    "    paths = [[\"left\",\"left\"],[\"left\",\"right\"],[\"right\",\"left\"],[\"right\",\"right\"]]\n",
    "    \n",
    "    for i in paths: \n",
    "        target = tree[i[0]][i[1]][\"prediction\"]\n",
    "        \n",
    "        if weight[weight.index == target].empty : \n",
    "            tree[i[0]][i[1]][\"prediction\"] = 0\n",
    "        else :\n",
    "            tree[i[0]][i[1]][\"prediction\"] = weight[weight.index == target].values[0][0]\n",
    "\n",
    "    return tree\n",
    "\n",
    "\n",
    "def predict(sample, rules):\n",
    "    prediction = None\n",
    "    while prediction is None:\n",
    "        feature, threshold = rules['feature'], rules['threshold']\n",
    "        if sample[feature] < threshold:\n",
    "            rules = rules['left']\n",
    "        else:\n",
    "            rules = rules['right']\n",
    "        prediction = rules.get('prediction', None)\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24abbf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_hist(df,k,feat):\n",
    "    m = len(df)\n",
    "    if k>m:\n",
    "        print(\"already satisfied\")\n",
    "        return df\n",
    "    else:\n",
    "        while k<m:\n",
    "            df = df.sort_values(by=[feat])\n",
    "            df.reset_index(inplace = True, drop = True)\n",
    "            a = list(df[feat])\n",
    "            b = [j-i for i, j in zip(a[:-1], a[1:])]\n",
    "\n",
    "            mini = b.index(min(b))\n",
    "\n",
    "            new = [(a[mini]+a[mini+1])/2,df[\"g\"][mini]+df[\"g\"][mini+1],df[\"h\"][mini]+df[\"h\"][mini+1]]\n",
    "\n",
    "            df.loc[len(df)] = new\n",
    "            df.drop([mini,mini+1], inplace = True)\n",
    "            m = len(df)\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d83ade8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    binned_client = []\n",
    "\n",
    "    for i in range(len(clients)):\n",
    "        #Compute gradient and hessian of each sample\n",
    "        clients[i][\"g\"] = 2*(clients[i][\"y\"]-f_m[i])*clients[i][\"y\"]\n",
    "        clients[i][\"h\"] = -2*clients[i][\"y\"]\n",
    "\n",
    "        hists = []\n",
    "        feature = list(clients[i].columns)\n",
    "        del feature[len(feature) - 3:]\n",
    "        b = 20\n",
    "\n",
    "        for j in feature:\n",
    "            df_bin = clients[i][[j,\"g\",\"h\"]].copy()\n",
    "            \n",
    "            df_bin[\"bin\"] = pd.qcut(df_bin[j],b,duplicates='drop')\n",
    "\n",
    "            df_bin = df_bin.groupby('bin', as_index=False)[['g','h']].sum()\n",
    "            df_bin[j] = df_bin[\"bin\"].apply(lambda x :x.mid)\n",
    "\n",
    "            df_bin.drop(\"bin\",axis = 1, inplace = True)\n",
    "\n",
    "            df_bin = df_bin[[j,\"g\",\"h\"]]\n",
    "            hists.append(df_bin)\n",
    "            \n",
    "        binned_client.append(hists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e1404d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done binning\n",
      "Ready to train tree\n",
      "Ready to search for leaf weight\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "################## Model 0 ###################\n",
    "f_0 = 0\n",
    "f_m = [f_0]*len(clients)\n",
    "\n",
    "trees = []\n",
    "\n",
    "################## Other models ###################\n",
    "for t in range(1,2):\n",
    "    \n",
    "    for i in range(len(clients)):\n",
    "        clients[i][\"g\"] = 2*(clients[i][\"y\"]-f_m[i])*clients[i][\"y\"]\n",
    "        clients[i][\"h\"] = -2*clients[i][\"y\"]\n",
    "\n",
    "    \n",
    "    feature = list(clients[i].columns)\n",
    "    del feature[len(feature) - 3:]\n",
    "\n",
    "    print(\"Done binning\")\n",
    "    ag = []\n",
    "    for j in feature:\n",
    "        aggregator = clients[0][[j,\"g\",\"h\"]]\n",
    "        for i in range(len(clients)):\n",
    "            aggregator = aggregator.append(clients[i][[j,\"g\",\"h\"]])\n",
    "        \n",
    "        #agg = merge_hist(aggregator, b,feature[j])\n",
    "        ag.append(aggregator)\n",
    "        \n",
    "    print(\"Ready to train tree\")\n",
    "    \n",
    "    tree_hist = split(ag,feature,0,2)\n",
    "    \n",
    "    print(\"Ready to search for leaf weight\")\n",
    "\n",
    "    tr = find_leaf_weights_cl(clients, tree_hist)\n",
    "    \n",
    "    trees.append(tr)\n",
    "    \n",
    "    for i in range(len(clients)):\n",
    "        preds = clients[i].apply(predict, axis='columns', rules=tr.copy())\n",
    "        f_m[i] = f_m[i]+preds    \n",
    "        \n",
    "    print(t)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "a2b46f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9526485729034824"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
